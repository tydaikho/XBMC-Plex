import re, urlparse, cgi, urllib, urllib2, cookielib, urlparsefrom datetime import datefrom BeautifulSoup import BeautifulSoupfrom htmlentitydefs import name2codepoint as n2cpimport sysUSER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22'def NormalizeURL(url):	#Log("*********** In PutLocker / Sockshare normalizeURL")	# Deal with special providerInfo URL built up by plugin to return	# info about this provider. For all other normal URLs, do nothing. 	if ("providerinfo" in url):			# Extract out domain.		match = re.search("(putlocker|sockshare)", url.lower())		if (match is None):			return url			try:			show = Prefs["show_" + match.group(1)]		except Exception, ex:			show = False					if (show):			return url + "&visible=true"		else:			return url				else:		return url		def MetadataObjectForURL(url): 	#Log('In MetadataObjectForURL for PutLocker / Sockshare (' + url + ')')		return VideoClipObject(		title = 'PutLocker / Sockshare Redirect Page',		summary = 'PutLocker / Sockshare Redirect Page',		thumb = None,	)def MediaObjectsForURL(url):	#Log('In MediaObjectsForURL for PutLocker / Sockshare (' + url + ')')		return [		MediaObject(			parts = [PartObject(key=Callback(PlayVideo, url=url))],		)	]	  	return ret@indirect	def PlayVideo(url):	putlocker_host = urlparse.urlparse(url).netloc		cj = cookielib.CookieJar()	opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))		# Request Provider page.	try:		#Log('Requesting ' + url)		request = urllib2.Request(url)		request.add_header('User-agent', USER_AGENT)		response = opener.open(request)			# Read in location and content of PutLocker page.			soup = BeautifulSoup(response.read())			provider_url = response.geturl()		#Log(provider_url)		if (provider_url.endswith('?404')):			return LogProviderError('Video no longer available (404 Returned)')				except Exception, ex:		return LogProviderError("Error whilst retrieving initial provider page (" + url + ")", ex)				# Read in form info...	try:		params = {}		params['hash'] = soup.find('input', {'name' : 'hash' })['value']		params['confirm'] = "Continue as Free User"		#Log(params)	except Exception, ex:		return LogProviderError("Error whilst retrieving information to go from intial page to next page", ex)		# Submit form by re-requesting the same page.	try:		#Log('Requesting ' + url)		request = urllib2.Request(url)		request.add_header('User-agent', USER_AGENT)		request.add_data(urllib.urlencode(params))		response = opener.open(request)				# Read in data from response.		content = response.read()		#Log(content)	except Exception, ex:		return LogProviderError("Error whilst retrieving second provider page (" + url + ")", ex)				# Look for playlist URL.	playlist_res = re.search("playlist: \'(.*?)\'", content)		if (playlist_res is None):				# Couldn't find playlist URL on page.		# Usually, that activates the download link, so try that.		soup = BeautifulSoup(content)		download_link = soup.find('a','download_file_link')		if download_link is None:			# No playlist and no download link. Might as well give up.			return LogProviderError('Playlist element not found on video page.')		else:			final_url =  "http://" + putlocker_host + decode_htmlentities(download_link['href'])						# Get final, final URL.			try:				#Log('Requesting ' + final_url)				request = urllib2.Request(final_url)				request.add_header('User-agent', USER_AGENT)				request.add_header('Accept-Encoding','gzip, deflate')								# Use an URL opener which doesn't follow 302s as otherwise we'll start				# to download the video.				opener_nofollow = urllib2.build_opener(					urllib2.HTTPCookieProcessor(cj),NoRedirectHandler()				)				response = opener_nofollow.open(request)							final_url = response.headers['Location']							except Exception, ex:				return LogProviderError("Error whilst retrieving playlist page (http://" + final_url + ")", ex)							else:			# We've got a playlist. Get the page and final url.		playlist = playlist_res.group(1)				#Log(playlist)				# Fetch playlist		try:			#Log('Requesting ' + "http://" + putlocker_host + playlist)			request = urllib2.Request("http://" + putlocker_host + playlist)			request.add_header('User-agent', USER_AGENT)			response = opener.open(request)					final = response.read()			#Log(final)					except Exception, ex:			return LogProviderError("Error whilst retrieving playlist page (http://" + putlocker_host + playlist + ")", ex)			final_url_res = re.search("<media:content url=\"(.*?)\"", final)				if (final_url_res is None):			return LogProviderError('Playlist did not containt valid video URL')		final_url = decode_htmlentities(final_url_res.group(1))		# Some content is hosted on a CDN which may issue a further 302 to another server.	# Plex should be able to follow this automatically, but let's add a note here as	# a reminder in case this ever breaks....		# Bit of a messy problem here....	#	# * Plex Laika client adds in a blank referer which provider does not like one bit.	#   So we need to override it. Because of problem 3 below, the only way to do this	#   is via adding httpHeaders in the URL which libCurl then parses.	# * Plex transcoding client does not add referer and doesn't understand extra http	#   headers in URL. So, no need to do anything, but really don't want to change the	#   URL or we'll end with an invalid url.	# * Neither seem to support httpHeaders added to ObjectContainer.	#	# So, need to manually set correct headers in the right client dependent way. <sigh>	# This will most likely break something at some point.	if (		Client.Platform == ClientPlatform.MacOSX or		Client.Platform == ClientPlatform.Linux or 		Client.Platform == ClientPlatform.Windows	):		# Plex will send blank refere if this isn't set which is reject by provider		final_url = final_url + "|Referer=" + url			Log(final_url)		oc = ObjectContainer(		objects = [			VideoClipObject(				items = [					MediaObject(						parts = [PartObject(key=final_url)]					)				]			)		]	)	# Might as well set a sensible user agent string.	oc.user_agent = USER_AGENT		return oc	# Utility methods.def LogProviderError(msg="", ex=None):	Log("************************** PROVIDER ERROR: " + msg)	raise Exception(msg)	return []# Replace encoded HTML entities with matching real character.def substitute_entity(match):	ent = match.group(3)		if match.group(1) == "#":		if match.group(2) == '':			return unichr(int(ent))		elif match.group(2) == 'x':			return unichr(int('0x'+ent, 16))	else:		cp = n2cp.get(ent)		if cp:			return unichr(cp)		else:			return match.group()			# Replace encoded HTML entities with matching real character.def decode_htmlentities(string):	entity_re = re.compile(r'&(#?)(x?)(\d{1,5}|\w{1,8});')	return entity_re.subn(substitute_entity, string)[0]	# urlib2 handler which doesn't automatically follow 302, but which instead returns the new# location.class NoRedirectHandler(urllib2.HTTPRedirectHandler):    def http_error_302(self, req, fp, code, msg, headers):        infourl = urllib.addinfourl(fp, headers, req.get_full_url())        infourl.status = code        infourl.code = code        return infourl